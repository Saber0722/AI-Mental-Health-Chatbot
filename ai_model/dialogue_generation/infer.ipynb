{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f21d92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b3d5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 23:40:20.516787: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-24 23:40:20.676579: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-24 23:40:20.676650: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-24 23:40:20.680038: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-24 23:40:20.680083: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-24 23:40:20.680096: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-24 23:40:21.085598: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-24 23:40:21.085864: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-24 23:40:21.085881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-05-24 23:40:21.085959: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-24 23:40:21.085988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ai_model/dialogue_generation/dialogue_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model=TFGPT2LMHeadModel.from_pretrained(\"ai_model/dialogue_generation/dialogue_model\")\n",
    "tokenizer=GPT2Tokenizer.from_pretrained(\"ai_model/dialogue_generation/dialogue_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a035160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c357d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dialogue(prompt, max_length=50, temperature=0.7, top_k=50):\n",
    "    # Encode the prompt\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"tf\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    # Generate response\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        temperature=temperature,  # Control randomness\n",
    "        top_k=top_k,             # Limit to top-k probable tokens\n",
    "        do_sample=True,          # Enable sampling for varied responses\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode the generated tokens\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e028805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I'm feeling a bit down today. Can you cheer me up?\n",
      "Response: I'm feeling a bit down today. Can you cheer me up?????????????????????????????????????\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "text = \"I'm feeling a bit down today. Can you cheer me up?\"\n",
    "response = generate_dialogue(text)\n",
    "print(\"Input:\", text)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19cdf8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Context: I just got a promotion at work! I'm so excited!\n",
      "Response:\n",
      "Response: Context: I just got a promotion at work! I'm so excited!\n",
      "Response:::::::::::::::::::::::::::::::::\n"
     ]
    }
   ],
   "source": [
    "text = \"Context: I just got a promotion at work! I'm so excited!\\nResponse:\"\n",
    "response = generate_dialogue(text)\n",
    "print(\"Input:\", text)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02975786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chart Configuration JSON:\n",
      "{\"type\": \"line\", \"data\": {\"labels\": [1], \"datasets\": [{\"label\": \"Training Loss\", \"data\": [0.0063034580089151], \"borderColor\": \"#1f77b4\", \"fill\": false}, {\"label\": \"Validation Loss\", \"data\": [7.63030220696237e-06], \"borderColor\": \"#ff7f0e\", \"fill\": false}, {\"label\": \"Validation Perplexity\", \"data\": [1.0000076291434103], \"borderColor\": \"#2ca02c\", \"fill\": false, \"yAxisID\": \"y2\"}]}, \"options\": {\"scales\": {\"y\": {\"title\": {\"display\": true, \"text\": \"Loss\"}, \"beginAtZero\": true}, \"y2\": {\"position\": \"right\", \"title\": {\"display\": true, \"text\": \"Perplexity\"}, \"beginAtZero\": true}, \"x\": {\"title\": {\"display\": true, \"text\": \"Epoch\"}}}, \"plugins\": {\"title\": {\"display\": true, \"text\": \"Training and Validation Metrics\"}}}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load training history\n",
    "history = pd.read_csv('data/dialogue_training_history.csv')\n",
    "\n",
    "# Create line chart for loss and perplexity\n",
    "chart_config = {\n",
    "    \"type\": \"line\",\n",
    "    \"data\": {\n",
    "        \"labels\": list(range(1, len(history) + 1)),\n",
    "        \"datasets\": [\n",
    "            {\n",
    "                \"label\": \"Training Loss\",\n",
    "                \"data\": history['loss'].tolist(),\n",
    "                \"borderColor\": \"#1f77b4\",\n",
    "                \"fill\": False\n",
    "            },\n",
    "            {\n",
    "                \"label\": \"Validation Loss\",\n",
    "                \"data\": history['val_loss'].tolist(),\n",
    "                \"borderColor\": \"#ff7f0e\",\n",
    "                \"fill\": False\n",
    "            },\n",
    "            {\n",
    "                \"label\": \"Validation Perplexity\",\n",
    "                \"data\": history['val_perplexity'].tolist(),\n",
    "                \"borderColor\": \"#2ca02c\",\n",
    "                \"fill\": False,\n",
    "                \"yAxisID\": \"y2\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"options\": {\n",
    "        \"scales\": {\n",
    "            \"y\": {\n",
    "                \"title\": {\"display\": True, \"text\": \"Loss\"},\n",
    "                \"beginAtZero\": True\n",
    "            },\n",
    "            \"y2\": {\n",
    "                \"position\": \"right\",\n",
    "                \"title\": {\"display\": True, \"text\": \"Perplexity\"},\n",
    "                \"beginAtZero\": True\n",
    "            },\n",
    "            \"x\": {\n",
    "                \"title\": {\"display\": True, \"text\": \"Epoch\"}\n",
    "            }\n",
    "        },\n",
    "        \"plugins\": {\n",
    "            \"title\": {\"display\": True, \"text\": \"Training and Validation Metrics\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Running the chart generation\n",
    "chart_json = json.dumps(chart_config)\n",
    "\n",
    "# DIsplay the chart configuration\n",
    "print(\"Chart Configuration JSON:\")\n",
    "print(chart_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601e326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
